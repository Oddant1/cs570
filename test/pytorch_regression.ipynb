{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as T  # non-standard alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, data_x, data_y, pct_close):\n",
    "  n_items = len(data_y)\n",
    "  X = T.Tensor(data_x)  # 2-d Tensor\n",
    "  Y = T.Tensor(data_y)  # actual as 1-d Tensor\n",
    "  oupt = model(X)  # all predicted as 2-d Tensor\n",
    "  pred = oupt.view(n_items)  # all predicted as 1-d\n",
    "  n_correct = T.sum((T.abs(pred - Y) < T.abs(pct_close * Y)))\n",
    "  result = (n_correct.item() * 100.0 / n_items)  # scalar\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(T.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.hid1 = T.nn.Linear(13, 10)  # 13-(10-10)-1\n",
    "    self.hid2 = T.nn.Linear(10, 10)\n",
    "    self.oupt = T.nn.Linear(10, 1)\n",
    "    T.nn.init.xavier_uniform_(self.hid1.weight)  # glorot\n",
    "    T.nn.init.zeros_(self.hid1.bias)\n",
    "    T.nn.init.xavier_uniform_(self.hid2.weight)\n",
    "    T.nn.init.zeros_(self.hid2.bias)\n",
    "    T.nn.init.xavier_uniform_(self.oupt.weight)\n",
    "    T.nn.init.zeros_(self.oupt.bias)\n",
    "\n",
    "  def forward(self, x):\n",
    "    z = T.tanh(self.hid1(x))\n",
    "    z = T.tanh(self.hid2(z))\n",
    "    z = self.oupt(z)  # no activation, aka Identity()\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Boston regression using PyTorch 1.0 \n",
      "\n",
      "Loading Boston data into memory \n",
      "Creating 13-(10-10)-1 DNN regression model \n",
      "\n",
      "Starting training\n",
      "Training complete \n",
      "\n",
      "Accuracy on test data = 0.00%\n",
      "For a town with raw input values: \n",
      "\n",
      "   0.092660   34.000000    6.090000    0.000000    0.433000 \n",
      "   6.495000   18.400000    5.491700    7.000000  329.000000 \n",
      "  16.100000  383.609985    8.670000 \n",
      "\n",
      "Predicted median house price = $21571.18\n"
     ]
    }
   ],
   "source": [
    "# 0. Get started\n",
    "print(\"\\nBoston regression using PyTorch 1.0 \\n\")\n",
    "T.manual_seed(1);  np.random.seed(1)\n",
    "# 1. Load data\n",
    "print(\"Loading Boston data into memory \")\n",
    "train_file = \"/home/anthony/src/school/cs570/cs570/test/data/Boston/train.csv\"\n",
    "test_file = \"/home/anthony/src/school/cs570/cs570/test/data/Boston/test.csv\"\n",
    "train_x = np.loadtxt(train_file, delimiter=\",\", usecols=range(0,13), dtype=np.float32)\n",
    "train_y = np.loadtxt(train_file, delimiter=\",\", usecols=[13], dtype=np.float32)\n",
    "test_x = np.loadtxt(test_file, delimiter=\",\", usecols=range(0,13), dtype=np.float32)\n",
    "test_y = np.loadtxt(test_file, delimiter=\",\", usecols=[13], dtype=np.float32)\n",
    "# 2. Create model\n",
    "print(\"Creating 13-(10-10)-1 DNN regression model \\n\")\n",
    "net = Net()  # all work done above\n",
    "# 3. Train model\n",
    "net = net.train()  # set training mode\n",
    "bat_size = 10\n",
    "loss_func = T.nn.MSELoss()  # mean squared error\n",
    "optimizer = T.optim.SGD(net.parameters(), lr=0.01)\n",
    "n_items = len(train_x)\n",
    "batches_per_epoch = n_items // bat_size\n",
    "max_batches = 1000 * batches_per_epoch\n",
    "print(\"Starting training\")\n",
    "for b in range(max_batches):\n",
    "    curr_bat = np.random.choice(n_items, bat_size,\n",
    "                                replace=False)\n",
    "X = T.Tensor(train_x[curr_bat])\n",
    "Y = T.Tensor(train_y[curr_bat]).view(bat_size,1)\n",
    "optimizer.zero_grad()\n",
    "oupt = net(X)\n",
    "loss_obj = loss_func(oupt, Y)\n",
    "loss_obj.backward()\n",
    "optimizer.step()\n",
    "if b % (max_batches // 10) == 0:\n",
    "    print(\"batch = %6d\" % b, end=\"\")\n",
    "    print(\"  batch loss = %7.4f\" % loss_obj.item(), end=\"\")\n",
    "    net = net.eval()\n",
    "    acc = accuracy(net, train_x, train_y, 0.15)\n",
    "    net = net.train()\n",
    "    print(\"  accuracy = %0.2f%%\" % acc)\n",
    "print(\"Training complete \\n\")\n",
    "# 4. Evaluate model\n",
    "\n",
    "# 5. Save model - TODO\n",
    "T.save(net.state_dict(), 'regr.pth')\n",
    "# 6. Use model\n",
    "raw_inpt = np.array([[0.09266, 34, 6.09, 0, 0.433, 6.495, 18.4,\n",
    "5.4917, 7, 329, 16.1, 383.61, 8.67]], dtype=np.float32)\n",
    "norm_inpt = np.array([[0.000970, 0.340000, 0.198148, -1,\n",
    "0.098765, 0.562177, 0.159629, 0.396666, 0.260870, 0.270992,\n",
    "0.372340, 0.966488, 0.191501]], dtype=np.float32)\n",
    "X = T.Tensor(norm_inpt)\n",
    "y = net(X)\n",
    "print(\"For a town with raw input values: \")\n",
    "for (idx,val) in enumerate(raw_inpt[0]):\n",
    "    if idx % 5 == 0: print(\"\")\n",
    "    print(\"%11.6f \" % val, end=\"\")\n",
    "print(\"\\n\\nPredicted median house price = $%0.2f\" %\n",
    "(y.item()*10000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
